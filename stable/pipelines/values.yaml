## Default values for pipelines

## For setting up external services
global:
  ## certificates added to this secret will be copied to $JFROG_HOME/pipelines/var/etc/security/keys/trusted directory
  customCertificates:
    enabled: false
    # certificateSecretName:
  ## Image Registry to pull images for Pipelines components from
  ## You can override it with your private Artifactory registry
  # imageRegistry: releases-docker.jfrog.io
  ## Internal Postgres must be set to false
  postgresql:
    host:
    port: 5432
    database: "pipelinesdb"
    user: "apiuser"
    # Password must be set
    password: ""
    url: ""
    ssl: false
    maxOpenConnections: 5
    minOpenConnections: 0
    idleTimeoutInSeconds: 10
    ## PostgreSQL password using existing secret
    # existingSecret: secret

  ## Internal Vault must be set to false
  vault:
    ## Vault url examples
    # external one: https://vault.example.com
    # internal one running in the same Kubernetes cluster: http://vault-active:8200
    url:
    token:
    ## Vault token using existing secret
    # existingSecret: secret

  # imagePullSecrets:
  #   - myRegistryKeySecretName
  ## Chart.AppVersion can be overidden using global.versions.pipelines, pipelines.version or image tags
  ## Note: Order of preference is 1) global.versions 2) pipelines.version 3) image tags 4) Chart.AppVersion
  versions: {}
  #   pipelines:
  # jfrogUrl:
  # jfrogUrlUi:
  # joinKey:
  # masterKey:

  ## Note: tags customInitContainersBegin,customInitContainers,customVolumes,customVolumeMounts,customSidecarContainers can be used both from global and application level simultaneously
  # customVolumes: |
  # customVolumeMounts: |
  ## Add custom init begin containers - first init container to run
  # customInitContainersBegin: |
  ## Add custom init containers - last init container to run
  # customInitContainers: |
  # customSidecarContainers: |

  ## Applies to pipelines pods
  nodeSelector: {}

## String to partially override pipelines.fullname template (will maintain the release name)
##
# nameOverride:

## String to fully override pipelines.fullname template
##
# fullnameOverride:

## Common
initContainer:
  image: "releases-docker.jfrog.io/alpine:3.14.2"
  pullPolicy: IfNotPresent

# Init containers
initContainers:
  resources:
    requests:
      memory: "50Mi"
      cpu: "10m"
    limits:
      memory: "1Gi"
      cpu: "1"


## Available modes: devmode (enable it for debuging) and production
runMode: production

## Image Registry to pull images for Pipelines components from
## You can override it with your private Artifactory registry
imageRegistry: releases-docker.jfrog.io

## For supporting pulling from private registries
## Secret type: kubernetes.io/dockerconfigjson
## Note: This is a breaking change from 1.x to 2.x (chart versions) of Pipelines chart
imagePullSecrets:
  # - myRegistryKeySecretName

## For supporting pulling k8s buildplane images (dind and reqKick) from private registries
## Secret type: kubernetes.io/dockerconfigjson
k8sImagePullSecret:

## Database configurations
## Use the wait-for-db init container. Set to false to skip
waitForDatabase: true

## Pipelines systemYaml override
## This is for advanced usecases where users wants to provide their own systemYaml for configuring pipelines
## Refer - https://www.jfrog.com/confluence/display/JFROG/Pipelines+System+YAML
## Note: This will override existing (default) .Values.pipelines.systemYaml in values.yaml
## Alternatively, systemYaml can be overidden via customInitContainers using external sources like vaults, external repositories etc. Please refer customInitContainer section for an example. Have to be set for both vault and pipelines
## Note: Order of preference is 1) customInitContainers 2) systemYamlOverride existingSecret 3) default systemYaml in values.yaml
## Note: From chart version 2.2.0 and above .Values.existingSecret is changed to .Values.systemYaml.existingSecret and .Values.systemYaml.dataKey
## Note: From chart version 2.3.7 and above `.Values.systemYaml` is changed to `.Values.systemYamlOverride`.
systemYamlOverride:
## You can use a pre-existing secret by specifying existingSecret
  existingSecret:
## The dataKey should be the name of the secret data key created.
  dataKey:

## String to partially override pipelines.fullname template (will maintain the release name)
# nameOverride:

## String to fully override pipelines.fullname template
# fullnameOverride:

## Set user/group to run Pipelines components with
securityContext:
  enabled: true
  uid: 1030
  gid: 1030

## Pipelines components
pipelines:

  # version:

  ## Artifactory URL - Mandatory
  ## If Artifactory and Pipelines are in same namespace, jfrogUrl is Artifactory service name, otherwise its external URL of Artifactory
  jfrogUrl: ""
  ## Artifactory UI URL - Mandatory
  ## This must be the external URL of Artifactory, for example: https://artifactory.example.com
  jfrogUrlUI: ""

  # unifiedSecretInstallation flag enables single unified secret holding all the pipelines secrets
  unifiedSecretInstallation: false
  # If flag is true then name of the unified secret is '{{ template "pipelines.name" . }}-unified-secret'
  # Update secret name to .Values.vault.server.extraVolumes
  # Update secret name to .Values.pipelines.customVolumes

  ## Join Key to connect to Artifactory
  ## IMPORTANT: You should NOT use the example joinKey for a production deployment!
  joinKey: EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
  ## Alternatively, you can use a pre-existing secret with a key called join-key by specifying joinKeySecretName
  ## Note: This feature is available on pipelines app version 1.9.x and later
  # joinKeySecretName:

  ## Pipelines requires a unique master key
  ## You can generate one with the command: "openssl rand -hex 32"
  ## IMPORTANT: You should NOT use the example masterKey for a production deployment!
  masterKey: FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
  ## Alternatively, you can use a pre-existing secret with a key called master-key by specifying masterKeySecretName.
  ## Note: This feature is available on pipelines app version 1.9.x and later
  # masterKeySecretName:

  ## certificates added to this secret will be copied to $JFROG_HOME/pipelines/var/etc/security/keys/trusted directory
  customCertificates:
    enabled: false
    # certificateSecretName:

  ## Installer Authentication Token
  ## The unique token can be generated with: uuidgen | tr '[:upper:]' '[:lower:]'
  authToken: "c7595edd-b63d-4fd6-9e1e-13924d6637f0"

  ## Pipelines ID in Artifactory
  ## For production, the unique ID should be generated instead of using 12345: openssl rand | tr -dc 1-9 | head -c 10
  serviceId: jfpip@12345

  ## Artifactory Service ID
  ## This should be set to the Artifactory Service ID
  artifactoryServiceId: "FFFFFFFFFFFF"

  ## Artifactory License ID
  ##
  licenseId: "FFFFFFFFF"

  rootBucket: jfrogpipelines

  mountPath: /opt/jfrog/pipelines/var/etc

  logPath: /opt/jfrog/pipelines/var/log

  replicaCount: 1

  # CORS configuration. Default values are artifactory url and www external url
  accessControlAllowOrigins_0: "update_with_artifactory_url"

  # RabbitMQ health check interval in mins
  rabbitmqHealthCheckIntervalInMins: 1
  # Artifactory health check interval in mins
  artifactoryHealthCheckIntervalInMins: 1
  # PostgresDB health check interval in mins
  dbHealthCheckIntervalInMins: 1
  # PostgressDB health check timeout in seconds
  dbHealthCheckTimeoutInSeconds: 2
  # BuildPlane polling interval
  nodePollerIntervalMS: 15000
  # Auto sync pipelineSource when resource is outdated
  autoSyncResourceIfOutdated: false
  # Allow static nodes
  allowCustomNodes: true
  # Enforce non root node pools
  enforceNonRootNodes: false
  # maximum step timeout value
  stepTimeoutMS: 21600000
  labels: {}
  updateStrategy: RollingUpdate

  nodeSelector: {}
  tolerations: []
  affinity: {}
  ## Only used if "affinity" is empty
  podAntiAffinity:
    ## Valid values are "soft" or "hard"; any other value indicates no anti-affinity
    type: "soft"
    topologyKey: "kubernetes.io/hostname"

  statefulset:
    annotations: {}

  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  schedulerName:

  # Create a priority class for the Pipelines pod or use an existing one
  # NOTE - Maximum allowed value of a user defined priority is 1000000000
  priorityClass:
    create: false
    value: 1000000000
    ## Override default name
    # name:
    ## Use an existing priority class
    # existingPriorityClass:

  ## retention policy settings
  retentionPolicy:
    enabled: false
    # how many days to keep pipelines state data
    maxAgeDays: 90
    # the minimum number of runs to keep data on per pipeline
    minRuns: 10

  ## metrics settings
  metrics:
    ## if enabled, metrics will be logged
    enabled: false
  ## Logging settings
  logging:
    ## Livelog settings
    view:
      ## If enabled, livelogs will be enabled
      enabled: false
      refreshRate: 10s
      concurrentSessionsPerUser: 10
      ## Provide the list of files for live logs
      # files:

    metrics:
      ## where metrics logs are written
      filePath: /opt/jfrog/pipelines/var/log/api-metrics_events.log
      ## if true, metrics will be logged to the console as well as the filePath
      console: false
      ## metrics logs rotation settings
      rotation:
        maxSizeMb: 25
        maxFiles: 10
        maxAgeDays: 365
        compress: true
        intervalMs: 900000

    application:
      level: warn
      loggerConfigResetTimeoutInSeconds: 1800
      rotation:
        maxSizeMb: 10
        maxFiles: 10
      streamToStdout: false

    request:
      rotation:
        maxSizeMb: 10
        maxFiles: 10
      streamToStdout: false

    metricsFramework:
      customMetricsCronFrequencyInMins: 360
      predefinedMetricsCronFrequencyInMins: 1
      rotation:
        maxSizeMb: 10
        maxFiles: 10

  signedPipelines:
    enabled: true
  ## Apply horizontal pod auto scaling on Pipelines pods
  ## Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 70
  ## JFConnect configuration
  ##
  jfconnect:
    enabled: false

  ## Extra environment variables that can be used to tune pipelines services to your needs.
  ## Uncomment and set value as needed
  extraEnvironmentVariables:
  # - name: MY_ENV_VAR
  #   value: "example_value"

  ## Add custom annotations for pipelines pods
  annotations: {}

  api:
    image:
      # registry:
      repository: jfrog/pipelines-api
      # tag:
      pullPolicy: IfNotPresent

    service:
      ## Supported service types: ClusterIP, NodePort and LoadBalancer
      type: ClusterIP
      port: 30000

      annotations:
      # external-dns.alpha.kubernetes.io/hostname:  example.org
      # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
      # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:XXXXXX:certificate/XXXXXX

      ## Set LB static IP
      loadBalancerIP:

      ## Whitelist IPs allowed to LoadBalancer type services
      ## Example: loadBalancerSourceRanges={82.82.190.51/32,141.141.8.8/32}
      loadBalancerSourceRanges: []
      newProbes: true
      healthCheck:
        intervalSecs: 120
      probes:
        liveness:
          failOnLongFailingReadiness:
            enabled: true
            failureDurationSecs: 60
    livenessProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.api.service.port }}/v1/system/liveness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 5
        successThreshold: 1

    startupProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.api.service.port }}/v1/system/readiness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 5
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 30

    ## External URL, it is ignored if ingress is enabled
    externalUrl:

    ingress:
      enabled: false
      annotations: {}
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"
      path: /
      className: ""
      hosts:
        - chart-example.local

      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local
      #      - chart-example.local

    resources: {}
      # limits:
      #   cpu: "2"
      #   memory: 4Gi
      # requests:
      #   cpu: 50m
      #   memory: 100Mi
  router:
    image:
      # registry:
      repository: jfrog/pipelines-router
      # tag:
      pullPolicy: IfNotPresent

    internalPort: 8046
    externalPort: 8082

    mountPath: "/opt/jfrog/router/var/etc"
    logPath: "/opt/jfrog/router/var/log"
    appStatePath: "/var/opt/jfrog/router/data"

    resources: {}
    #  requests:
    #    memory: "50Mi"
    #    cpu: "10m"
    #  limits:
    #    memory: "1Gi"
    #    cpu: "1"
    livenessProbe:
      enabled: false
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.router.internalPort }}/router/api/v1/system/liveness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}90{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 3
        successThreshold: 1

    readinessProbe:
      enabled: false
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.router.internalPort }}/router/api/v1/system/readiness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}60{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 5
        successThreshold: 1

    startupProbe:
      enabled: false
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.router.externalPort }}/router/api/v1/system/readiness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 5
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 30

  www:
    image:
      # registry:
      repository: jfrog/pipelines-www
      # tag:
      pullPolicy: IfNotPresent

    service:
      ## Supported service types: ClusterIP, NodePort and LoadBalancer
      type: ClusterIP
      port: 30001

      annotations:
      # external-dns.alpha.kubernetes.io/hostname:  example.org
      # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
      # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:XXXXXX:certificate/XXXXXX

      ## Set LB static IP
      loadBalancerIP:

      ## Whitelist IPs allowed to LoadBalancer type services
      ## Example: loadBalancerSourceRanges={82.82.190.51/32,141.141.8.8/32}
      loadBalancerSourceRanges: []
    livenessProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.www.service.port }}/v1/system/liveness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 5
        successThreshold: 1

    startupProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.www.service.port }}/v1/system/readiness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 5
        successThreshold: 1

    resources: {}
      # limits:
      #   cpu: 800m
      #   memory: 900Mi
      # requests:
      #   cpu: 10m
      #   memory: 40Mi


  frontend:
    image:
      # registry:
      repository: jfrog/pipelines-frontend
      # tag:
      pullPolicy: IfNotPresent
    internalPort: 30042
    livenessProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.frontend.internalPort }}/index.html
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}20{{ else }}0{{ end }}
        periodSeconds: 10
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        failureThreshold: 5
        successThreshold: 1

    resources: {}
      # limits:
      #   cpu: 800m
      #   memory: 900Mi
      # requests:
      #   cpu: 10m
      #   memory: 40Mi

  nodepoolmanager:
    image:
      # registry:
      repository: jfrog/pipelines-nodepoolmanager
      # tag:
      pullPolicy: IfNotPresent
    resources: {}
    enabled: false
    # limits:
    #   cpu: 500m
    #   memory: 500Mi
    # requests:
    #   cpu: 5m
    #   memory: 40Mi


  msg:
    uiUser: monitor
    # Password must be set
    uiUserPassword: ""

  pipelineSync:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: "2"
      #   memory: 500Mi
      # requests:
      #   cpu: 25m
      #   memory: 40Mi

  runTrigger:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  stepTrigger:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  cron:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  nexec:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

    enabled: true

  hookHandler:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 25m
      #   memory: 40Mi

  marshaller:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 60Mi

  logup:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  extensionSync:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  templateSync:
    image:
      repository: jfrog/pipelines-micro
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  reqSealer:
    image:
      # registry:
      repository: jfrog/pipelines-micro
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 500m
      #   memory: 500Mi
      # requests:
      #   cpu: 5m
      #   memory: 40Mi

  observability:
    image:
      # registry:
      repository: jfrog/pipelines-observability
      # tag:
      pullPolicy: IfNotPresent
    # name: observability
    internalPort: 8036
    logPath: "/opt/jfrog/observability/var/log"

    resources:
      # requests:
      #   memory: "100Mi"
      #   cpu: "101Mi"
      # limits:
      #   memory: "500Mi"
      #   cpu: "200Mi"
    livenessProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.observability.internalPort }}/api/v1/system/liveness
        initialDelaySeconds: {{ if semverCompare "<v1.20.0-0" .Capabilities.KubeVersion.Version }}180{{ else }}0{{ end }}
        failureThreshold: 5
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
        periodSeconds: 10
        successThreshold: 1

    startupProbe:
      enabled: true
      config: |
        exec:
          command:
            - sh
            - -c
            - curl --fail --max-time {{ .Values.probes.timeoutSeconds }} http://localhost:{{ .Values.pipelines.observability.internalPort }}/api/v1/system/readiness
        initialDelaySeconds: 30
        failureThreshold: 90
        periodSeconds: 5
        timeoutSeconds: {{ .Values.probes.timeoutSeconds }}

  ## Pipelines installer
  pipelinesInit:
    image:
      # registry:
      repository: jfrog/pipelines-installer
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

  # Add any list of configmaps to Pipelines
  configMaps: |
  #  posthook-start.sh: |-
  #    echo "This is a post start script"
  #  posthook-end.sh: |-
  #    echo "This is a post end script"

  ## Add custom volumes
  # If .Values.pipelines.unifiedSecretInstallation is true then secret name should be '{{ template "pipelines.name" . }}-unified-secret'
  customVolumes: |
  #  - name: custom-script
  #    configMap:
  #      name: custom-script

  ## Add custom volumesMounts
  customVolumeMounts: |
  #  - name: custom-script
  #    mountPath: /scripts/script.sh
  #    subPath: script.sh

  # Add custom persistent volume mounts - Available to the entire namespace
  customPersistentVolumeClaim: {}
  #  name:
  #  mountPath:
  #  accessModes:
  #   - "-"
  #  size:
  #  storageClassName:

  ## Add custom init begin containers - first init container to run
  customInitContainersBegin: |
  #  - name: "custom-begin-setup"
  #    image: "{{ .Values.initContainer.image }}"
  #    imagePullPolicy: "{{ .Values.initContainer.pullPolicy}}"
  #    securityContext:
  #      runAsNonRoot: true
  #      allowPrivilegeEscalation: false
  #      capabilities:
  #        drop:
  #          - NET_RAW
  #    command:
  #      - 'sh'
  #      - '-c'
  #      - 'touch {{ .Values.pipelines.mountPath }}/example-custom-setup'
  #    volumeMounts:
  #      - mountPath: "{{ .Values.pipelines.mountPath}}"
  #        name: jfrog-pipelines-folder

  ## Add custom init containers - last init container to run
  customInitContainers: |
  #  - name: "custom-systemyaml-setup"
  #    image: "{{ .Values.initContainer.image }}"
  #    imagePullPolicy: "{{ .Values.initContainer.pullPolicy}}"
  #    securityContext:
  #      runAsNonRoot: true
  #      allowPrivilegeEscalation: false
  #      capabilities:
  #        drop:
  #          - NET_RAW
  #    command:
  #      - 'sh'
  #      - '-c'
  #      - 'curl -o {{ .Values.pipelines.mountPath }}/system.yaml https://<repo-url>/systemyaml'
  #    volumeMounts:
  #      - mountPath: "{{ .Values.pipelines.mountPath}}"
  #        name: jfrog-pipelines-folder

  ## Add custom sidecar containers
  # - The provided example uses a custom volume (customVolumes)
  customSidecarContainers: |
  #  - name: "sidecar-list-etc"
  #    image: "{{ .Values.initContainer.image }}"
  #    imagePullPolicy: "{{ .Values.initContainer.pullPolicy }}"
  #    securityContext:
  #      runAsNonRoot: true
  #      allowPrivilegeEscalation: false
  #      capabilities:
  #        drop:
  #          - NET_RAW
  #    command:
  #      - 'sh'
  #      - '-c'
  #      - 'sh /scripts/script.sh'
  #    volumeMounts:
  #      - mountPath: "{{ .Values.pipelines.mountPath }}"
  #        name: volume
  #      - mountPath: "/scripts/script.sh"
  #        name: custom-script
  #        subPath: script.sh
  #    resources:
  #      requests:
  #        memory: "32Mi"
  #        cpu: "50m"
  #      limits:
  #        memory: "128Mi"
  #        cpu: "100m"

  # Add custom secrets - secret per file
  # If .Values.pipelines.unifiedSecretInstallation is true then secret name should be '{{ template "pipelines.name" . }}-unified-secret'
  customSecrets:
  #  - name: custom-secret
  #    key: custom-secret.yaml
  #    data: >
  #      custom_secret_config:
  #        parameter1: value1
  #        parameter2: value2
  #  - name: custom-secret2
  #    key: custom-secret2.config
  #    data: |
  #      here the custom secret 2 config


  systemYaml: |
    {{- if .Values.router.routerConfiguration }}
    router:
      ## Router configuration
      topology:
        external:
          refresh:
            interval: "{{ .Values.router.topology.external.refresh.interval }}"
        local:
          healthCheck:
            interval: "{{ .Values.router.healthCheck.interval }}"
            requestTimeout: "{{ .Values.router.healthCheck.requestTimeout }}"
            healthyThreshold: "{{ .Values.router.healthCheck.healthyThreshold }}"
            unhealthyThreshold: "{{ .Values.router.healthCheck.unhealthyThreshold }}"
      serviceRegistry:
        url: "{{ .Values.router.serviceRegistry.url }}"
        insecure: {{ .Values.router.serviceRegistry.insecure }}
    {{- end }}
    shared:
      ## Artifactory configuration
      ##
      artifactory:
        ## Artifactory URL
        ##
        baseUrl: "{{ tpl (required "\n\npipelines.jfrogUrl or global.jfrogUrl is required! This allows to connect to Artifactory.\nYou can copy the JFrog URL from Admin > Security > Settings" (include "pipelines.jfrogUrl" .)) . }}"
        ## Unified UI URL
        ##
        baseUrlUI: "{{ tpl (required "\n\npipelines.jfrogUrlUI or global.jfrogUrlUI is required!" (include "pipelines.jfrogUrlUI" .)) . }}"
        ## Pipelines Service ID
        ##
        serviceId: "{{ .Values.pipelines.serviceId }}"
        ## Artifactory Service ID
        ##
        artifactoryServiceId: "{{ .Values.pipelines.artifactoryServiceId }}"
        ## Artifactory License ID
        ##
        licenseId: "{{ .Values.pipelines.licenseId }}"
        ## Proxy to connect to Artifactory
        ##
        proxy:
          url: ""
          username: ""
          password: ""

      ## JFConnect configuration
      ##
      jfconnect:
        enabled: {{ .Values.pipelines.jfconnect.enabled }}

      ## Routers configuration
      ##
      router:
        ip: ""
        accessPort: {{ .Values.pipelines.router.internalPort }}
        dataPort: {{ .Values.pipelines.router.externalPort }}

      ## Database configuration
      ##
      db:
        type: "postgres"
        maxOpenConnections: {{ .Values.global.postgresql.maxOpenConnections }}
        minOpenConnections: {{ .Values.global.postgresql.minOpenConnections }}
        idleTimeoutInSeconds: {{ .Values.global.postgresql.idleTimeoutInSeconds }}
        {{- if .Values.postgresql.enabled }}
        ip: {{ tpl .Release.Name . }}-postgresql
        port: "{{ .Values.postgresql.service.port }}"
        name: {{ .Values.postgresql.postgresqlDatabase }}
        username: {{ .Values.postgresql.postgresqlUsername }}
        password: "{{ .Values.postgresql.postgresqlPassword }}"
        {{- else }}
        ip: {{ tpl .Values.global.postgresql.host . }}
        port: "{{ .Values.global.postgresql.port }}"
        name: {{ .Values.global.postgresql.database }}
        username: {{ .Values.global.postgresql.user }}
        password: "{{ .Values.global.postgresql.password }}"
        {{- end }}
        externalUrl: ""
        {{- if .Values.global.postgresql.url }}
        connectionString: "{{ .Values.global.postgresql.url }}"
        {{- else if .Values.postgresql.enabled }}
        connectionString: "{{ tpl (printf "postgres://%s:%s@%s-postgresql:%v/%s" .Values.postgresql.postgresqlUsername .Values.postgresql.postgresqlPassword .Release.Name .Values.postgresql.service.port .Values.postgresql.postgresqlDatabase) . }}"
        {{- else if and (not .Values.postgresql.enabled) (.Values.global.postgresql.ssl) }}
        connectionString: "{{ tpl (printf "postgres://%s:%s@%v:%v/%s?sslmode=require" .Values.global.postgresql.user .Values.global.postgresql.password .Values.global.postgresql.host .Values.global.postgresql.port .Values.global.postgresql.database) . }}"
        {{- else }}
        connectionString: "{{ tpl (printf "postgres://%s:%s@%v:%v/%s" .Values.global.postgresql.user .Values.global.postgresql.password .Values.global.postgresql.host .Values.global.postgresql.port .Values.global.postgresql.database) . }}"
        {{- end }}

      ## RabbitMQ configuration
      ##
      msg:
        {{- if .Values.rabbitmq.enabled }}
        ip: {{ .Release.Name }}-rabbitmq
        port: {{ .Values.rabbitmq.service.port }}
        adminPort: {{ .Values.rabbitmq.service.managerPort }}
        erlangCookie: {{ .Values.rabbitmq.auth.erlangCookie }}
        username: {{ .Values.rabbitmq.auth.username }}
        password: "{{ .Values.rabbitmq.auth.password }}"
        defaultExchange: pipelinesEx
        amqpVhost: pipelines
        amqpRootVhost: pipelinesRoot
        {{- else }}
        ip: {{ tpl .Values.rabbitmq.internal_ip . }}
        port: {{ .Values.rabbitmq.port}}
        adminPort: {{ .Values.rabbitmq.manager_port }}
        erlangCookie: {{ .Values.rabbitmq.erlang_cookie }}
        username: {{ .Values.rabbitmq.ms_username }}
        password: "{{ .Values.rabbitmq.ms_password }}"
        defaultExchange: {{ .Values.rabbitmq.root_vhost_exchange_name }}
        amqpVhost: {{ .Values.rabbitmq.build_vhost_name}}
        amqpRootVhost: {{ .Values.rabbitmq.root_vhost_name }}
        protocol: {{ .Values.rabbitmq.protocol }}
        {{- end }}
        queues:
          - "core.pipelineSync"
          - "core.runTrigger"
          - "core.stepTrigger"
          - "core.marshaller"
          - "cluster.init"
          - "core.logup"
          - "www.signals"
          {{- if .Values.pipelines.nexec.enabled }}
          - "core.nexec"
          {{- end }}
          - "core.hookHandler"
          - "core.extensionSync"
          - "core.templateSync"
          - "core.reqSealer"
        ui:
          {{- if .Values.rabbitmq.enabled }}
          username: {{ .Values.pipelines.msg.uiUser }}
          password: "{{ .Values.pipelines.msg.uiUserPassword }}"
          {{- else }}
          protocol: http
          username: {{ .Values.rabbitmq.cp_username }}
          password: "{{ .Values.rabbitmq.cp_password }}"
          {{- end }}
        external:
          ## URL for build plane VMs to access RabbitMQ
          {{- if .Values.rabbitmq.externalUrl }}
          url: {{ .Values.rabbitmq.externalUrl }}
          {{- else if .Values.rabbitmq.enabled }}
          url: amqp://{{ tpl .Release.Name . }}-rabbitmq
          {{- else }}
          url: {{ .Values.rabbitmq.protocol }}://{{ tpl .Values.rabbitmq.msg_hostname . }}:{{ .Values.rabbitmq.port }}
          {{- end }}
          rootUrl: ""
          adminUrl: ""
        {{- if not .Values.rabbitmq.enabled }}
        build:
          username: {{ .Values.rabbitmq.build_username }}
          password: "{{ .Values.rabbitmq.build_password }}"
        {{- end }}

      ## Vault configuration
      ##
      vault:
        {{- if .Values.vault.enabled }}
        port: {{ .Values.vault.server.service.port }}
        {{- if .Values.vault.server.ha.enabled }}
        ip: {{ .Release.Name }}-vault-active
        url: http://{{ .Release.Name }}-vault-active:{{ .Values.vault.server.service.port }}
        {{- else }}
        ip: {{ .Release.Name }}-vault
        url: http://{{ .Release.Name }}-vault:{{ .Values.vault.server.service.port }}
        {{- end }}
        {{- else }}
        url: {{ .Values.global.vault.url }}
        {{- end }}
        ## DO NOT CHANGE THE TOKEN VALUE!!!
        token: "_VAULT_TOKEN_"
        unsealKeys:
          - ""
          - ""
          - ""
          - ""
          - ""

      ## Redis configuration
      ##
      redis:
        ip: {{ .Release.Name }}-redis-master
        port: {{ .Values.redis.redisPort }}

        clusterEnabled: false

      ## Metrics logging
      metrics:
        enabled: {{ .Values.pipelines.metrics.enabled }}
      logging:

        view:
          enabled: {{ .Values.pipelines.logging.view.enabled }}
          refreshRate: {{ .Values.pipelines.logging.view.refreshRate }}
          concurrentSessionsPerUser: {{ .Values.pipelines.logging.view.concurrentSessionsPerUser }}
          {{- if .Values.pipelines.logging.view.files }}
          files: "{{ .Values.pipelines.logging.view.files }}"
          {{- end }}

        metrics:
          filePath: {{ .Values.pipelines.logging.metrics.filePath }}
          console: {{ .Values.pipelines.logging.metrics.console }}
          rotation:
            maxSizeMb: {{ .Values.pipelines.logging.metrics.rotation.maxSizeMb }}
            maxFiles: {{ .Values.pipelines.logging.metrics.rotation.maxFiles }}
            maxAgeDays: {{ .Values.pipelines.logging.metrics.rotation.maxAgeDays }}
            compress: {{ .Values.pipelines.logging.metrics.rotation.compress }}
            intervalMs: {{ .Values.pipelines.logging.metrics.rotation.intervalMs }}

        application:
          level: {{ .Values.pipelines.logging.application.level }}
          loggerConfigResetTimeoutInSeconds: {{ .Values.pipelines.logging.application.loggerConfigResetTimeoutInSeconds }}
          rotation:
            maxSizeMb: {{ .Values.pipelines.logging.application.rotation.maxSizeMb }}
            maxFiles: {{ .Values.pipelines.logging.application.rotation.maxFiles }}
          streamToStdout: {{ .Values.pipelines.logging.application.streamToStdout }}

        request:
          rotation:
            maxSizeMb: {{ .Values.pipelines.logging.request.rotation.maxSizeMb }}
            maxFiles: {{ .Values.pipelines.logging.request.rotation.maxFiles }}
          streamToStdout: {{ .Values.pipelines.logging.request.streamToStdout }}

        metricsFramework:
          customMetricsCronFrequencyInMins: {{ .Values.pipelines.logging.metricsFramework.customMetricsCronFrequencyInMins }}
          predefinedMetricsCronFrequencyInMins: {{ .Values.pipelines.logging.metricsFramework.predefinedMetricsCronFrequencyInMins }}
          rotation:
            maxSizeMb: {{ .Values.pipelines.logging.metricsFramework.rotation.maxSizeMb }}
            maxFiles: {{ .Values.pipelines.logging.metricsFramework.rotation.maxFiles }}

    ## This section is used for bringing up the core services and setting up
    ## configurations required by the installer & the services
    ##
    core:
      ## id is automatically determined based on the current hostname
      ## or set using the SHARED_NODE_ID environment variable.
      ##
      id: "afd8df9d08bf257ae9b7d7dbbf348b7a3a574ebdd3a61d350d4b64e3129dee85"
      installerIP: "1.2.3.4"
      installerAuthToken: "{{ .Values.pipelines.authToken }}"
      installerImage: "jfrog/pipelines-installer"
      registryUrl: "{{ .Values.imageRegistry }}"
      {{- if .Values.k8sImagePullSecret }}
      imageRegistrySecret: "{{ .Values.k8sImagePullSecret }}"
      {{- end }}
      os: "Ubuntu_16.04"
      osDistribution: "xenial"
      architecture: "x86_64"
      dockerVersion: ""
      runMode: "{{ .Values.runMode }}"
      user: ""
      group: ""
      noVerifySsl: false
      ignoreTLSErrors: false
      controlplaneVersion: {{ include "pipelines.app.version" . }}
      buildplaneVersion: {{ include "pipelines.app.version" . }}
      accessControlAllowOrigins:
        - {{ .Values.pipelines.accessControlAllowOrigins_0 }}
        - {{ .Values.pipelines.accessControlAllowOrigins_1 }}
      rabbitmqHealthCheckIntervalInMins: {{ .Values.pipelines.rabbitmqHealthCheckIntervalInMins}}
      artifactoryHealthCheckIntervalInMins: {{ .Values.pipelines.artifactoryHealthCheckIntervalInMins}}
      dbHealthCheckIntervalInMins: {{ .Values.pipelines.dbHealthCheckIntervalInMins }}
      dbHealthCheckTimeoutInSeconds: {{ .Values.pipelines.dbHealthCheckTimeoutInSeconds }}
      autoSyncResourceIfOutdated: {{ .Values.pipelines.autoSyncResourceIfOutdated}}
      ## Global proxy settings, to be applied to all services
      ##
      proxy:
        httpProxy: ""
        httpsProxy: ""
        noProxy: ""
        username: ""
        password: ""

      ## Mailserver settings
      ##
      mailserver:
        host: ""
        port: ""
        username: ""
        password: ""
        tls: ""
        ssl: ""
      apiRetryIntervalMs: 3000
      accountSyncFrequencyHr: 1
      hardDeleteIntervalInMins: 60
      configBackupCount: 5
      lastUpdateTime: ""
      callHomeUrl:  "https://api.bintray.com/products/jfrog/pipelines/stats/usage"
      allowCallHome: true
      serviceInstanceHealthCheckIntervalInMins: 1
      serviceInstanceStatsCutOffIntervalInHours: 24
      {{- if or .Values.pipelines.customCertificates.enabled .Values.global.customCertificates.enabled }}
      customCACertsPath: "{{ .Values.pipelines.mountPath }}/security/keys/trusted"
      {{- else }}
      customCACertsPath: ""
      {{- end }}
      signedPipelinesEnabled: {{ .Values.pipelines.signedPipelines.enabled }}

      retentionPolicy:
        enabled: {{ .Values.pipelines.retentionPolicy.enabled }}
        maxAgeDays: {{ .Values.pipelines.retentionPolicy.maxAgeDays }}
        minRuns: {{ .Values.pipelines.retentionPolicy.minRuns }}

      ## Service configuration
      ##
      services:
        api:
          name: {{ include "pipelines.api.name" . }}
          port: {{ .Values.pipelines.api.service.port }}
          {{- if (and .Values.pipelines.api.ingress.enabled .Values.pipelines.api.ingress.tls) }}
          {{- range .Values.pipelines.api.ingress.hosts }}
          externalUrl: https://{{ . }}
          {{- end }}
          {{- else if .Values.pipelines.api.ingress.enabled }}
          {{- range .Values.pipelines.api.ingress.hosts }}
          externalUrl: http://{{ . }}
          {{- end }}
          {{- else if .Values.pipelines.api.externalUrl }}
          externalUrl: {{ .Values.pipelines.api.externalUrl }}
          {{- else if .Values.pipelines.jfrogUrlUI }}
          externalUrl: {{ .Values.pipelines.jfrogUrlUI }}/pipelines/api
          {{- else }}
          externalUrl: {{ .Values.global.jfrogUrlUI }}/pipelines/api
          {{- end }}
          newProbes: {{ .Values.pipelines.api.service.newProbes }}
          healthCheck:
            intervalSecs: {{ .Values.pipelines.api.service.healthCheck.intervalSecs }}
          probes:
            liveness:
              failOnLongFailingReadiness:
                enabled: {{ .Values.pipelines.api.service.probes.liveness.failOnLongFailingReadiness.enabled }}
                failureDurationSecs: {{ .Values.pipelines.api.service.probes.liveness.failOnLongFailingReadiness.failureDurationSecs }}
        www:
          name: {{ include "pipelines.www.name" . }}
          port: {{ .Values.pipelines.www.service.port }}
          sessionSecret: "{{ .Values.pipelines.authToken }}"
        frontend:
          name: {{ include "pipelines.frontend.name" . }}
          port: {{ .Values.pipelines.frontend.internalPort }}
          sessionSecret: "{{ .Values.pipelines.authToken }}"
        pipelineSync:
          name: pipelineSync
        runTrigger:
          name: runTrigger
        stepTrigger:
          name: stepTrigger
        cron:
          name: cron
        {{- if .Values.pipelines.nexec.enabled }}
        nexec:
          name: nexec
        {{- end }}
        hookHandler:
          name: hookHandler
        marshaller:
          name: marshaller
        extensionSync:
          name: extensionSync
        templateSync:
          name: templateSync
        reqSealer:
          name: reqSealer
        logup:
          name: logup

    ## Runtime configuration
    ##
    runtime:
      rootBucket: "{{ .Values.pipelines.rootBucket }}"
      defaultMinionCount: 1
      nodeCacheIntervalMS: 600000
      jobConsoleBatchSize: 10
      jobConsoleBufferIntervalMs: 3
      maxDiskUsagePercentage: 90
      stepTimeoutMS: {{ .Values.pipelines.stepTimeoutMS }}
      nodeStopDayOfWeek: 0
      nodeStopIntervalDays: 30
      maxNodeCheckInDelayMin: 15
      nodePollerIntervalMS: {{ .Values.pipelines.nodePollerIntervalMS }}
      defaultMinionInstanceSize: "c4.large"
      allowDynamicNodes: true
      allowCustomNodes: {{ .Values.pipelines.allowCustomNodes }}
      enforceNonRootNodes: {{ .Values.pipelines.enforceNonRootNodes }}
      {{- range $key, $value := .Values.runtimeOverride }}
      {{ $key }}: {{ $value | quote }}
      {{- end }}
      languageImages:
        - architecture: x86_64
          os: Ubuntu_18.04
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u18node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: Ubuntu_18.04
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u18go
          defaultVersion: 1.19
        - architecture: x86_64
          os: Ubuntu_18.04
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u18java
          defaultVersion: 17
        - architecture: x86_64
          os: Ubuntu_18.04
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u18cpp
          defaultVersion: 10
        - architecture: ARM64
          os: Ubuntu_20.04
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u20node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: Ubuntu_20.04
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u20node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: Ubuntu_20.04
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u20java
          defaultVersion: 17
        - architecture: x86_64
          os: Ubuntu_20.04
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u20cpp
          defaultVersion: 10
        - architecture: x86_64
          os: Ubuntu_20.04
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-u20go
          defaultVersion: 1.19
        - architecture: x86_64
          os: CentOS_7
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: CentOS_7
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7java
          defaultVersion: 17
        - architecture: x86_64
          os: CentOS_7
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7cpp
          defaultVersion: 3
        - architecture: x86_64
          os: CentOS_7
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7go
          defaultVersion: 1.19
        - architecture: x86_64
          os: CentOS_8
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: CentOS_8
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8java
          defaultVersion: 17
        - architecture: x86_64
          os: CentOS_8
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8cpp
          defaultVersion: 9
        - architecture: x86_64
          os: CentOS_8
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8go
          defaultVersion: 1.19
        - architecture: x86_64
          os: WindowsServer_2019
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19node
          defaultVersion: 16
        - architecture: x86_64
          os: WindowsServer_2019
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19java
          defaultVersion: 11
        - architecture: x86_64
          os: WindowsServer_2019
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19cpp
          defaultVersion: 10
        - architecture: x86_64
          os: WindowsServer_2019
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19go
          defaultVersion: 1.19
        - architecture: x86_64
          os: WindowsServer_2019
          language: dotnet
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19dotnet
          isDefault: true
          defaultVersion: 6
        - architecture: x86_64
          os: WindowsServer_2019
          language: dotnetcore
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-w19dotnetcore
          defaultVersion: 3
        - architecture: x86_64
          os: RHEL_7
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: RHEL_7
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7java
          defaultVersion: 17
        - architecture: x86_64
          os: RHEL_7
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7cpp
          defaultVersion: 3
        - architecture: x86_64
          os: RHEL_7
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c7go
          defaultVersion: 1.19
        - architecture: x86_64
          os: RHEL_8
          language: node
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8node
          isDefault: true
          defaultVersion: 16
        - architecture: x86_64
          os: RHEL_8
          language: java
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8java
          defaultVersion: 17
        - architecture: x86_64
          os: RHEL_8
          language: cpp
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8cpp
          defaultVersion: 9
        - architecture: x86_64
          os: RHEL_8
          language: go
          registryUrl: releases-docker.jfrog.io
          image: jfrog/pipelines-c8go
          defaultVersion: 1.19

## Runtime Override Properties Section
runtimeOverride: {}

# Router Configuration
router:
  routerConfiguration: false
  topology:
    external:
      refresh:
        interval: "3s"
  healthCheck:
    interval: 10s
    requestTimeout: 10s
    healthyThreshold: 1
    unhealthyThreshold: 5
  serviceRegistry:
    url:
    insecure: false

# PostgreSQL
## https://hub.helm.sh/charts/bitnami/postgresql
## Configuration values for the postgresql dependency
## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md
##
postgresql:
  enabled: true
  image:
    registry: releases-docker.jfrog.io
    repository: bitnami/postgresql
    tag: 13.4.0-debian-10-r39
  postgresqlDatabase: "pipelinesdb"
  postgresqlUsername: "apiuser"
  # Password must be set
  postgresqlPassword: ""
  ## PostgreSQL password using existing secret
  # existingSecret: secret
  ## Mount PostgreSQL secret as a file instead of passing environment variable
  # usePasswordFile: false
  postgresqlExtendedConf:
    listenAddresses: "*"
    maxConnections: "1500"
  service:
    port: 5432
  persistence:
    enabled: true
    size: 100Gi
    # existingClaim:
  primary:
    nodeSelector: {}
    affinity: {}
    tolerations: []
  readReplicas:
    nodeSelector: {}
    affinity: {}
    tolerations: []
  resources: {}
  #  requests:
  #    memory: "1Gi"
  #    cpu: "250m"
  #  limits:
  #    memory: "2Gi"
  #    cpu: "1"

## RabbitMQ HA
## https://hub.helm.sh/charts/bitnami/rabbitmq
## Configuration values for the rabbitmq dependency
## ref: https://github.com/kubernetes/charts/blob/master/stable/rabbitmq/README.md
## Important: This is a breaking change from 6.x to 7.x of rabbitmq chart - https://github.com/bitnami/charts/tree/master/bitnami/rabbitmq#to-700
## Note: This would impact upgrading from 1.x to 2.x (chart versions) Pipelines chart
rabbitmq:
  enabled: true
  protocol: amqps
  replicaCount: 1
  image:
    registry: releases-docker.jfrog.io
    repository: bitnami/rabbitmq
    tag: 3.9.21-debian-11-r0
  auth:
    username: admin

    ## RabbitMQ application password
    ## ref: https://github.com/bitnami/bitnami-docker-rabbitmq#environment-variables
    # Password must be set
    password: ""
    # existingPasswordSecret: name-of-existing-secret

    ## Erlang cookie to determine whether different nodes are allowed to communicate with each other
    erlangCookie: PIPELINESRABBITMQCLUSTER
    # existingErlangSecret: name-of-existing-secret

  extraPlugins: ""
  maxAvailableSchedulers: null
  onlineSchedulers: null
  ## Additional environment variables to set
  ## ref: https://github.com/bitnami/charts/tree/master/bitnami/rabbitmq#adding-extra-environment-variables
  extraEnvVars:
    - name: RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS
      value: "+S 2:2 +sbwt none +sbwtdcpu none +sbwtdio none"

  persistence:
    enabled: true
    size: 20Gi

  resources: {}

  affinity: {}

## Redis
## Configuration values for the redis dependency
## ref: https://github.com/bitnami/charts/tree/master/bitnami/redis
##
redis:
  enabled: true
  serviceAccount:
    create: false
    name: ""
  image:
    registry: releases-docker.jfrog.io
    repository: bitnami/redis
    tag: 6.2.1-debian-10-r9
  redisPort: 6379

  cluster:
    enabled: false
    slaveCount: 2

  usePassword: false

  master:
    configmap: |-
      appendonly yes
      loglevel notice
    resources: {}
    #  requests:
    #    memory: 100Mi
    #    cpu: 25m
    #  limits:
    #    memory: 4Gi
    #    cpu: "1"

    affinity: {}

  slave:
    resources: {}
    #  requests:
    #    memory: 100Mi
    #    cpu: 25m
    #  limits:
    #    memory: 4Gi
    #    cpu: "1"

    affinity: {}

## Vault
vault:
  enabled: true

  global:
    imagePullSecrets: []
    #  - name: image-pull-secret

  injector:
    # Must be disabled
    enabled: false

  server:
    image:
      repository: "releases-docker.jfrog.io/hashicorp/vault"
      tag: 1.8.6

    # resources: {}
    #  requests:
    #    memory: 256Mi
    #    cpu: 250m
    #  limits:
    #    memory: 256Mi
    #    cpu: 250m

    # Affinity Settings
    # Commenting out or setting as empty the affinity variable, will allow
    # deployment to single node services such as Minikube
    affinity: |
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ template "vault.name" . }}
                app.kubernetes.io/instance: "{{ .Release.Name }}"
                component: server
            topologyKey: kubernetes.io/hostname

    # Toleration Settings for server pods
    # This should be a multi-line string matching the Toleration array
    # in a PodSpec.
    tolerations: null

    # Enables network policy for server pods
    networkPolicy:
      enabled: false
      egress: []
      # egress:
      # - to:
      #   - ipBlock:
      #       cidr: 10.0.0.0/24
      #   ports:
      #   - protocol: TCP
      #     port: 443

    service:
      port: 8200

    # A list of init containers. Specified as a YAML list.
    extraInitContainers:
      # wait-for-db is checking if postgresql server up
      - name: vault-wait-for-db
        image: "releases-docker.jfrog.io/alpine:3.14.2"
        imagePullPolicy: IfNotPresent
        env:
          - name: CONNECTION_DETAILS
            valueFrom:
              secretKeyRef:
                name: vault-storage-config
                key: postgresql-connection
        command:
          - 'sh'
          - '-c'
          - >
            echo "Waiting for Postgres to come up..."; until nc -z -w 2 ${CONNECTION_DETAILS} && echo database ok; do
              sleep 2;
            done; sleep 10;

      # create-vault-table is creating vault schema changes in postgres db
      - name: create-vault-table
        image: releases-docker.jfrog.io/bitnami/postgresql:13.4.0-debian-10-r39
        imagePullPolicy: IfNotPresent
        env:
          - name: DATABASE_URL
            valueFrom:
              secretKeyRef:
                name: vault-storage-config
                key: postgresql-url
        command:
          - 'sh'
          - '-c'
          - >
            echo "Creating Vault Tables...";
            psql ${DATABASE_URL} -f /vault/userconfig/vault-storage-config/vault.sql;
            psql ${DATABASE_URL} -c "\dt;";
        volumeMounts:
          - name: userconfig-vault-storage-config
            mountPath: /vault/userconfig/vault-storage-config

    # Set Pipelines vault-init sidecar container
    extraContainers:
      - name: vault-init
        image: releases-docker.jfrog.io/jfrog/pipelines-vault-init:1.20.4
        imagePullPolicy: IfNotPresent
        env:
          - name: CHECK_INTERVAL
            value: "10s"
          - name: VAULT_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: VAULT_ADDRESS
            value: "http://localhost:8200"
        resources:
          requests:
            memory: 10Mi
            cpu: 10m
          limits:
            memory: 50Mi
            cpu: 50m

    # Pass path of the storage config file with an external Postgres setup
    extraArgs: "-config=/vault/userconfig/vault-storage-config/config.hcl"

    # Secret name with the storage config file for Postgres connection
    # It will be exposed to Vault in the path "/vault/userconfig/vault-storage-config/"
    # If .Values.pipelines.unifiedSecretInstallation is true then secret name should be '{{ template "pipelines.name" . }}-unified-secret'
    extraVolumes:
      - type: secret
        name: vault-storage-config

    dataStorage:
      ## Must be disabled
      enabled: false

    # `updateStrategyType` must be set to `OnDelete` update strategy for HA setup
    # https://www.vaultproject.io/docs/platform/k8s/helm/run#upgrading-vault-on-kubernetes
    # It is critical to use OnDelete instead of RollingUpdate because standbys must be updated
    # before the active primary. A failover to an older version of Vault must always be avoided.
    updateStrategyType: "RollingUpdate"

    ha:
      enabled: false
      replicas: 1

      config: |
        ui = false

        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }

        disable_mlock = true
        service_registration "kubernetes" {}

    livenessProbe:
      enabled: true
      path: "/v1/sys/health?standbyok=true"
      initialDelaySeconds: 50

    serviceAccount:
      create: true
      name: vault

  ## Vault Postgres and storage config using existing secret
  # It will be exposed to Vault in the path "/vault/userconfig/vault-storage-config/"
  # existingSecret: vault-storage-config

  ## Role Based Access for vault-init container
  ## Ref: https://kubernetes.io/docs/admin/authorization/rbac/
  rbac:
    role:
      ## Rules to create. It follows the role specification
      rules:
      - apiGroups:
        - ''
        resources:
        - secrets
        verbs:
        - "*"

# Filebeat Sidecar container
## The provided filebeat configuration is for Pipeline logs. It assumes you have a logstash installed and configured properly.
filebeat:
  enabled: false
  name: pipelines-filebeat
  image:
    repository: "docker.elastic.co/beats/filebeat"
    version: 7.16.2
  logstashUrl: "logstash:5044"

  terminationGracePeriod: 10

  livenessProbe:
    exec:
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          curl --fail 127.0.0.1:5066
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5

  readinessProbe:
    exec:
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          filebeat test output
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5

  resources: {}
#    requests:
#      memory: "100Mi"
#      cpu: "100m"
#    limits:
#      memory: "100Mi"
#      cpu: "100m"

  filebeatYml: |
    logging.level: info
    path.data: {{ .Values.pipelines.logPath }}/filebeat
    name: pipelines-filebeat
    queue.spool:
      file:
        permissions: 0760
    filebeat.inputs:
    - type: log
      enabled: true
      close_eof: ${CLOSE:false}
      paths:
         - {{ .Values.pipelines.logPath }}/*.log
      fields:
        service: "jfpip"
        log_type: "pipelines"
    output:
      logstash:
         hosts: ["{{ .Values.filebeat.logstashUrl }}"]

## Role Based Access Control
## Ref: https://kubernetes.io/docs/admin/authorization/rbac/
rbac:
  create: false
  role:
    ## Rules to create. It follows the role specification
    rules:
    - apiGroups:
      - ''
      resources:
      - services
      - endpoints
      - pods
      verbs:
      - get
      - watch
      - list

serviceAccount:
  create: false
  ## The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the fullname template
  name:
  ## Service Account annotations
  annotations: {}
  ## Explicitly mounts the API credentials for the Service Account
  automountServiceAccountToken: false

networkpolicy:
  # Allows all ingress and egress
  - name: pipelines
    podSelector:
      matchLabels:
        app.kubernetes.io/name: pipelines
    egress:
    - {}
    ingress:
    - {}
  # #Uncomment to allow only pipelines pods to communicate with rabbitmq (if rabbitmq.enabled is true)
  # - name: rabbitmq
  #   podSelector:
  #     matchLabels:
  #       app.kubernetes.io/name: rabbitmq
  #   ingress:
  #   - from:
  #     - podSelector:
  #         matchLabels:
  #           app.kubernetes.io/name: pipelines

## The Build Plane is where the actual builds will run
buildPlane:
  ## Dynamic Build Plane integration for the initial bootstrapping of the build planes.
  ## Any required changes post install need to be done in UI: Administration/Pipelines/Integrations
  dynamic:
    ## customer part is not needed for on-prem install
    customer:
      accountId: ""
      nodePoolName: ""
      nodelimit: ""
    provider:
      aws:
        enabled: false
        ## Replace the dummy values with the real ones
        nodePoolName: "aws-dynamic-node-pool"
        nodelimit: "3"
        instanceType: c4.xlarge
        securityGroupId: testsecuritygroupId
        subnetId: test-subnetId
        keyPairName: testaccountSSHKeyPair
        vpcId: testVPCId
        region: us-east-1
        ##
        accessKey: ""
        secretKey: ""
        ## Existing secret with AWS keys
        existingSecret:
      k8s:
        enabled: false
        ## Replace the dummy values with the real ones
        nodePoolName: "k8s-dynamic-node-pool"
        nodelimit: "3"
        cpu: "1"
        memory: "1000"
        namespace: default
        storageClass: standard
        ## Node Affinity values: {key1:value1,key2:value2}
        labels:
        ## Kubernetes node pool kubeconfig base64 encoded
        kubeconfig: ""
        ## Existing secret with kubeconfig
        existingSecret:

## Allows to add additional kubernetes resources
## Use --- as a separator between multiple resources
additionalResources: |

# Adding entries to a Pod's /etc/hosts file
# For an example, refer - https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases
hostAliases: []
#  - ip: "127.0.0.1"
#    hostnames:
#      - "foo.local"
#      - "bar.local"
#  - ip: "10.1.2.3"
#    hostnames:
#      - "foo.remote"
#      - "bar.remote"

## Specify common probes parameters
probes:
  timeoutSeconds: 10
