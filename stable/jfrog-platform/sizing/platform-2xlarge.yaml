artifactory:
  ##############################################################################################
  # The 2xlarge sizing
  # This size is intended for very large organizations. It can be increased with adding replicas
  # [WARNING] Some of the configuration mentioned in this file are taken inside system.yaml
  # hence this configuration will be overridden when enabling systemYamlOverride
  ##############################################################################################
  splitServicesToContainers: true
  artifactory:
    # Enterprise and above licenses are required for setting replicaCount greater than 1.
    # Count should be equal or above the total number of licenses available for artifactory.
    replicaCount: 6
  
    # Require multiple Artifactory pods to run on separate nodes
    podAntiAffinity:
      type: "hard"
  
    resources:
      requests:
        cpu: "4"
        memory: 20Gi
      limits:
        # cpu: "20"
        memory: 24Gi
  
    extraEnvironmentVariables:
      - name: MALLOC_ARENA_MAX
        value: "16"
      - name: SKIP_WAIT_FOR_EXTERNAL_DB
        value: "true"
  
    javaOpts:
      other: >
        -XX:InitialRAMPercentage=40
        -XX:MaxRAMPercentage=70
        -Dartifactory.async.corePoolSize=200
        -Dartifactory.async.poolMaxQueueSize=100000
        -Dartifactory.http.client.max.total.connections=150
        -Dartifactory.http.client.max.connections.per.route=150
        -Dartifactory.access.client.max.connections=200
        -Dartifactory.metadata.event.operator.threads=5
        -XX:MaxMetaspaceSize=512m
        -Djdk.nio.maxCachedBufferSize=1048576
        -XX:MaxDirectMemorySize=1024m
    tomcat:
      connector:
        maxThreads: 800
        extraConfig: 'acceptCount="1200" acceptorThreadCount="2" compression="off" connectionLinger="-1" connectionTimeout="120000" enableLookups="false"'
  
    database:
      maxOpenConnections: 200
  
  access:
    tomcat:
      connector:
        maxThreads: 200
    javaOpts:
      other: >
        -XX:InitialRAMPercentage=20
        -XX:MaxRAMPercentage=60
    database:
      maxOpenConnections: 200
    resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        # cpu: "2"
        memory: 4Gi
    extraEnvironmentVariables:
      - name: MALLOC_ARENA_MAX
        value: "16"
      - name: SKIP_WAIT_FOR_EXTERNAL_DB
        value: "true"
  
  router:
    resources:
      requests:
        cpu: "2"
        memory: 2Gi
      limits:
        # cpu: "12"
        memory: 4Gi
  
  frontend:
    resources:
      requests:
        cpu: "1"
        memory: 500Mi
      limits:
        # cpu: "5"
        memory: 1Gi
  
  metadata:
    database:
      maxOpenConnections: 200
    resources:
      requests:
        cpu: "1"
        memory: 500Mi
      limits:
        # cpu: "5"
        memory: 2Gi
  
  event:
    resources:
      requests:
        cpu: 200m
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 500Mi
  
  observability:
    resources:
      requests:
        cpu: 200m
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 500Mi
  
  jfconnect:
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 250Mi
  
  jfconfig:
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        memory: 150Mi
    extraEnvironmentVariables:
      - name: MALLOC_ARENA_MAX
        value: "8"      
  
  topology:
    resources:
      requests:
        cpu: 100m
        memory: 1000Mi
      limits:
        memory: 1500Mi
    extraEnvironmentVariables:
      - name: MALLOC_ARENA_MAX
        value: "8"
  
  onemodel:
    resources:
      requests:
        cpu: 225m
        memory: 180Mi
      limits:
        # cpu: "1"
        memory: 250Mi
  
  nginx:
    replicaCount: 3
    disableProxyBuffering: true
    resources:
      requests:
        cpu: "4"
        memory: "6Gi"
      limits:
        # cpu: "14"
        memory: "8Gi"
  
  postgresql:
    primary:
      extendedConfiguration: |
        max_connections = 5000
      affinity:
        # Require PostgreSQL pod to run on a different node than Artifactory pods
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - artifactory
              topologyKey: kubernetes.io/hostname
      resources:
        requests:
          memory: 256Gi
          cpu: "64"
        limits:
          memory: 256Gi
          # cpu: "128"
  
  evidence:
    resources:
      requests:
        cpu: 500m
        memory: 4Gi
      limits:
        # cpu: "2"
        memory: 4Gi
  
  rtfs:
    resources:
      requests:
        cpu: 500m
        memory: 3500Mi
      limits:
        # cpu: "2"
        memory: 3500Mi
xray:
  ##############################################################
  # The 2xlarge sizing
  # This size is intended for large organizations. It can be increased with adding replicas
  ##############################################################
  
  replicaCount: 3
  databaseUpgradeReady: true
  waitForDatabase: true
  unifiedUpgradeAllowed: true
  
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 12
    targetCPUUtilizationPercentage: 200
    targetMemoryUtilizationPercentage: 800
  
  xray:
    podAntiAffinity:
      ## Valid values are "soft" or "hard"; any other value indicates no anti-affinity
      type: "hard"
      topologyKey: "kubernetes.io/hostname"
  
  analysis:
    resources:
      requests:
        cpu: "100m"
        memory: 250Mi
      limits:
        # cpu: "4"
        memory: 10Gi
  
  indexer:
    resources:
      requests:
        cpu: "300m"
        memory: 550Mi
      limits:
        # cpu: "6"
        memory: 8Gi
  
  persist:
    resources:
      requests:
        cpu: "100m"
        memory: 250Mi
      limits:
        # cpu: "4"
        memory: 8Gi
  
  server:
    resources:
      requests:
        cpu: "200m"
        memory: 500Mi
      limits:
        # cpu: "4"
        memory: 6Gi
  
  router:
    resources:
      requests:
        cpu: "60m"
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 1Gi
  
  observability:
    resources:
      requests:
        cpu: "10m"
        memory: 25Mi
      limits:
        # cpu: "1"
        memory: 250Mi
  
  panoramic:
    enabled: false
    resources:
      requests:
        cpu: "100m"
        memory: 250Mi
      limits:
        # cpu: "4"
        memory: 8Gi
  
  sbom:
    enabled: false
    resources:
      requests:
        cpu: "100m"
        memory: 250Mi
      limits:
        # cpu: "4"
        memory: 10Gi
  
  policyenforcer:
    resources:
      requests:
        memory: "250Mi"
        cpu: "60m"
      limits:
        memory: "8Gi"
        cpu: "4"
  
  # PostgreSQL
  ## Configuration values for the postgresql dependency
  ## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md
  ##
  postgresql:
    resources:
      requests:
        memory: 128Gi
        cpu: "32"
      limits:
        memory: 128Gi
        # cpu: "64"
    primary:
      extendedConfiguration: |
        max_connections = 2000
        listen_addresses = '*'
      affinity:
        # Require PostgreSQL pod to run on a different node than Xray pods
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - xray
              topologyKey: kubernetes.io/hostname
  
  rabbitmq:
    extraConfiguration: |-
      vm_memory_high_watermark.absolute = 6G
      {{- if not .Values.global.xray.rabbitmq.haQuorum.enabled }}
      raft.wal_max_size_bytes = 1048576
      {{- end }}
    resources:
      requests:
        cpu: "500m"
        memory: 1Gi
      limits:
        # cpu: "8"
        memory: 7Gi
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - xray
            topologyKey: kubernetes.io/hostname
distribution:
  ##############################################################
  # The 2xlarge sizing
  # This size is intended for very large organizations. It can be increased with adding replicas
  ##############################################################
  
  unifiedUpgradeAllowed: true
  databaseUpgradeReady: true
  
  replicaCount: 3
  
  distribution:
    resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        # cpu: "4"
        memory: 3Gi
  
    extraEnvironmentVariables:
      - name: MALLOC_ARENA_MAX
        value: "2"
  
    javaOpts:
      other: >
        -XX:InitialRAMPercentage=40
        -XX:MaxRAMPercentage=70
        -XX:+UseStringDeduplication
        -XX:MaxMetaspaceSize=300m
        -Djdk.nio.maxCachedBufferSize=262144
        -XX:MaxDirectMemorySize=256m
  
  router:
    resources:
      requests:
        cpu: 50m
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 1Gi
  
  observability:
    resources:
      requests:
        cpu: 25m
        memory: 50Mi
      limits:
        # cpu: "1"
        memory: 250Mi
  
  redis:
    resources:
      requests:
        cpu: 50m
        memory: 100Mi
      limits:
        # cpu: "1"
        memory: 1Gi
  
  postgresql:
    primary:
      extendedConfiguration: |
        max_connections = 5000
      affinity:
        # Require PostgreSQL pod to run on a different node than distribution pods
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - distribution
              topologyKey: kubernetes.io/hostname
      resources:
        requests:
          cpu: "150m"
          memory: 1Gi
        limits:
          # cpu: "2"
          memory: 8Gi

